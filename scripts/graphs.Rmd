---
title: "Graphs"
output: html_notebook
---

```{r}
source("db.R")
source("functions.R")
```

# How to run

```{r}
OUTPUT_DIR = "/data/ecoop17/graphs/oopsla17"
```

# Getting the data

To create the graphs, the following is required:

- access to UCI database using `UCI_USERNAME`, `UCI_PASSWORD` and `UCI_HOST` variables
- local database using the `DB_USER`, `DB_PASSWORD` and `DB_HOST`
- completion of all the preprocessing steps required to produce the heatmaps and aggregation csvs 

The following specified paths to the dataset folders. The dataset folders should contain the required files, `heatmap.csv` and `scc_groups_uci.txt` for JavaScript, Python, Java and C++ and extra `groups_scc.csv` and `aggegated.files.csv` for JavaScript.

```{r}
JS_FOLDER = "/data/ecoop17/datasets/jsHalf"
JS_NONPM_FOLDER = "/data/ecoop17/datasets/jsHalf_nonpm"
PYTHON_FOLDER = "/data/ecoop17/datasets/python"
JAVA_FOLDER = "/data/ecoop17/datasets/java"
CPP_FOLDER = "/data/ecoop17/datasets/cpp"
```

Furthermore, names of the databases containing the datasets must be specified:

```{r}
DB_JS = DB_JS
DB_JS_NONPM = DB_JS_NONPM
DB_PYTHON = DB_PYTHON
DB_JAVA = DB_JAVA
DB_CPP = DB_CPP
```

## Loading the data

### Heatmaps

```{r}
read.heatmap = function(path) {
    read.csv(paste.path(path, "heatmap.csv"), header = F, col.names = c("pid", "stars", "commits", "files", "originalFiles","containsClones"))
}

heatmap_js = read.heatmap(JS_FOLDER)
heatmap_cpp = read.heatmap(CPP_FOLDER)
heatmap_java = read.heatmap(JAVA_FOLDER)
heatmap_python = read.heatmap(PYTHON_FOLDER)
```

### SourcererCC groups

These files were obtained from Pedro. 

> How to generate them? 

```{r}
read.scc_groups = function(path) {
    read.csv(paste.path(path, "scc_groups_uci.txt"), colClasses = c("NULL", "NULL", "integer"), header = T, sep = ",") 
}

scc_js = read.scc_groups(JS_FOLDER)
scc_cpp = read.scc_groups(CPP_FOLDER)
scc_java = read.scc_groups(JAVA_FOLDER)
scc_python = read.scc_groups(PYTHON_FOLDER)
```

Now download the JavaScript special clone groups:

> We can generate this for other languages as well (see `sccpreprocessor group`)

```{r}
js_scc = read.csv(paste.path(JS_FOLDER, "groups_scc.csv"), header = F, col.names = c("id", "files"))
```

### JavaScript aggregated data

```{r}
js_aggregate = read.table(paste.path(JS_FOLDER,"aggregated.files.csv"), header = F, col.names = c("time", 1:64), colClasses = rep("integer", 65))
```

# Common questions for graphs

## Figure 2 - Heatmap

See `heatmaps.Rmd` for details how to preprocess data and build heatmaps. 

## Figure 2

This is an excel graph and is not generated by this script.

## Figure 3 duplicate token hash groups distributions

    SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash
    
```{r}
logHistogram("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash", "C++", "Clone Group Size", "% of groups", "file-clone-group-sizes-cpp.pdf", dbname = DB_CPP, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash", "Java", "Clone Group Size", "% of groups", "file-clone-group-sizes-java.pdf", dbname = DB_JAVA, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash", "Python", "Clone Group Size", "% of groups", "file-clone-group-sizes-python.pdf", dbname = DB_PYTHON, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash", "JavaScript", "Clone Group Size", "% of groups", "file-clone-group-sizes-js.pdf")
```

And for JavaScript using NPM and non-NPM:

```{r}
logHistogramDouble("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash", DB_JS, "all", DB_JS_NONPM, "no NPM", "JavaScript", "Clone Group Size", "% of projects", "file-clone-group-sizes-js2.pdf")
```

## Figure 4 SourcererCC clone groups distributions

> Using Pedro's data:

```{r}
logHistogramFromDF(scc_js, "nclones", "JavaScript", "Number of clones", "Number of Files", "clone-dist-js.pdf", summary = F)
logHistogramFromDF(scc_cpp, "nclones", "C++", "Number of clones", "Number of Files", "clone-dist-cpp.pdf", summary = F)
logHistogramFromDF(scc_java, "nclones", "Java", "Number of clones", "Number of Files", "clone-dist-java.pdf", summary = F)
logHistogramFromDF(scc_python, "nclones", "Python", "Number of clones", "Number of Files", "clone-dist-python.pdf", summary = F)
```

For JS from our data:

> Not used in the paper

```{r}
logHistogramFromDF(js_scc, "files", "JavaScript", "Number of clones", "Number of Files", "clone-dist-js-ours.pdf", summary = F)
```

## Figure 5 File-level duplication excluding small files

This is an excel graph and is not generated by this script.

## Figure 6 Percentage of project clones at various levels of overlap

This is an excel graph and is not generated by this script.

## Figure 7 JavaScript files over time

```{r}
cols <- c(
    "non-test duplicates"="#a0a0a0",
    "test duplicates"="#808080",
    "npm non-test"="#606060",
    "npm test"="#404040",
    "unique tests"="#202020",
    "unique files"="#000000"
    )
data = data.frame(
    time = js_aggregate$time,
    unique = sum(js_aggregate, npm = F, thUnique = T, tests = F),
    uniqueTests = sum(js_aggregate, npm = F, thUnique = T),
    npmTests = sum(js_aggregate, npm = T, tests = T),
    npmNonTest = sum(js_aggregate, npm = T),
    dupTests = sum(js_aggregate, npm = F, thUnique = F, tests = T),
    all = sum(js_aggregate))
g = ggplot(data, aes(x = time))
g = g + geom_area(aes(y = all, fill = "non-test duplicates"))
g = g + geom_area(aes(y = dupTests + npmNonTest + uniqueTests, fill = "test duplicates"))
g = g + geom_area(aes(y = npmNonTest + uniqueTests, fill = "npm non-test"))
g = g + geom_area(aes(y = npmTests + uniqueTests, fill = "npm test"))
g = g + geom_area(aes(y = uniqueTests, fill = "unique tests"))
g = g + geom_area(aes(y = unique, fill = "unique files"))
g = g + scale_x_continuous("Date", limits = c(87, 212), labels = function(x) sapply(x, month.text))
g = g + scale_y_continuous("Files", labels = plain)
#g = g + scale_fill_identity(guide = 'legend', labels = c("haha", "bubu", "gaga"))
#g = g + guides(fill=guide_legend(title="New Legend Title"))
g = g + scale_fill_manual(name = "Legend", values=cols, breaks = names(cols))
g = g + ggtitle("Files over time")
g = g + theme(plot.title = element_text(hjust = 0.5))
ggsave(paste.path(OUTPUT_DIR, "time_js_files_bw.pdf"), width = 68 * 2.5, height = 55 * 2.5, units = "mm")
g
```

## Figure 8 Non-npm files over time

```{r}
cols <- c(
    "non-test duplicates"="#c0c0c0",
    "test duplicates"="#808080",
    "unique tests"="#404040",
    "unique files"="#000000",
    "NPM files" = "dashed"
    )
data = data.frame(
    time = aggregate$time,
    unique = sum(js_aggregate, npm = F, thUnique = T, tests = F),
    uniqueTests = sum(js_aggregate, npm = F, thUnique = T),
    dupTests = sum(js_aggregate, npm = F, thUnique = F, tests = T),
    dup = sum(js_aggregate, npm = F),
    npm = sum(js_aggregate, npm = T))
g = ggplot(data, aes(x = time))
g = g + geom_area(aes(y = dup, fill = "non-test duplicates"))
g = g + geom_area(aes(y = dupTests + uniqueTests, fill = "test duplicates"))
g = g + geom_area(aes(y = uniqueTests, fill = "unique tests"))
g = g + geom_area(aes(y = unique, fill = "unique files"))
g = g + geom_line(aes(y = npm, linetype = "NPM files"))
g = g + scale_x_continuous("Date", limits = c(87, 212), labels = function(x) sapply(x, month.text))
g = g + scale_y_continuous("Files", limits = c(0, max(data$dup)), labels = plain)
g = g + scale_fill_manual(name = "Legend", values=cols, breaks = names(cols))
g = g + scale_linetype_manual(name=" ", values = cols)
g = g + ggtitle("Non - NPM Files over time")
g = g + theme(plot.title = element_text(hjust = 0.5))
ggsave(paste.path(OUTPUT_DIR, "time_js_files_nonpm_bw.pdf"), width = 68 * 2.5, height = 55 * 2.5, units = "mm")
g
```

## Figure 9 % of non unique files over time

```{r}
cols <- c(
    "# of all files"="#c0c0c0",
    "# of NPM files"="#a0a0a0",
    "all files" = "solid",
    "NPM" = "dotted",
    "non-NPM" = "dashed",
    "non-NPM tests" = "dotdash"
    )
x = sum(js_aggregate)
maxx = max(x)
minx = min(x)
data = data.frame(
    time = aggregate$time,
    all = sum(js_aggregate) * 30 / maxx,
    npm = sum(js_aggregate, npm = T) * 30 / maxx,
    pctAll = 100 - sum(js_aggregate, thUnique = T) * 100 / sum(js_aggregate),
    pctNPM = 100 - sum(js_aggregate, npm = T, thUnique = T) * 100 / sum(js_aggregate,npm = T),
    pctNonNPM = 100 - sum(js_aggregate, npm = F, thUnique = T) * 100 / sum(js_aggregate, npm = F),
    pctNonNPMTest = 100 - sum(js_aggregate, npm = F, tests = T, thUnique = T) * 100 / sum(js_aggregate, npm = F, tests = T))
g = ggplot(data, aes(x = time))
g = g + geom_area(aes(y = all, fill = "# of all files"), position = position_nudge(y = 70))
g = g + geom_area(aes(y = npm, fill = "# of NPM files"), position = position_nudge(y = 70))
g = g + geom_line(aes(y = pctAll, linetype = "all files"))
g = g + geom_line(aes(y = pctNPM, linetype = "NPM"))
g = g + geom_line(aes(y = pctNonNPM, linetype = "non-NPM"))
g = g + geom_line(aes(y = pctNonNPMTest, linetype = "non-NPM tests"))
g = g + scale_x_continuous("Date", limits = c(109, 212), labels = function(x) sapply(x, month.text), breaks = c(106,118, 130, 142, 154, 166, 178, 190, 202, 212))
g = g + scale_y_continuous("%", labels = plain)
g = g + coord_cartesian(ylim = c(70, 100))
g = g + scale_fill_manual(name = "Legend", values=cols, breaks = names(cols))
g = g + scale_linetype_manual(name=" ", values = cols)
g = g + ggtitle("% of non-unique files")
g = g + theme(plot.title = element_text(hjust = 0.5))
ggsave(paste.path(OUTPUT_DIR,"time_js_dup_bw.pdf"), width = 68 * 2.5, height = 55 * 2.5, units = "mm")
g
```

## Figure 10 - % of NPM files 

    SELECT 100 - (y.files / x.files) * 100  FROM jsHalf.projects AS x JOIN jsHalf_nonpm.projects AS y ON x.projectId = y.projectId WHERE x.files != y.files LIMIT 100; 

```{r}
normalHistogram("SELECT 100 - (y.files / x.files) * 100  FROM jsHalf.projects AS x JOIN jsHalf_nonpm.projects AS y ON x.projectId = y.projectId WHERE x.files != y.files", "% of NPM files", "% of NPM files", "% of projects", "npm_proj_pct.pdf")
```

## Figure 11 - Direct imports per module

    SELECT COUNT(DISTINCT blameModule) FROM files_nm JOIN files ON files_nm.fileId = files.fileId WHERE npmDepth > 0 GROUP BY projectId;

```{r}
normalHistogram("SELECT COUNT(DISTINCT blameModule) FROM files_nm JOIN files ON files_nm.fileId = files.fileId WHERE npmDepth > 0 GROUP BY projectId", "Direct Imports per Module", "# of modules directly imported", "% of projects", "npm_direct.pdf")
```


## Figure 12 - Popularity of NPM modules
    
    CREATE TABLE npm_popularity SELECT blameName AS module COUNT(DISTINCT projectId) AS count FROM files_nm JOIN files ON files_nm.fileId = files.fileId WHERE npmDepth > 0 GROUP BY blameModule;
    
```{r}
normalHistogramLogY("SELECT count FROM npm_popularity WHERE count >= 0", "Module popularity", "How many projects directly import a module", "# of modules", "npm_pop.pdf")
```

## Figure 13 - Files per project log

```{r}
logHistogramFromDF(heatmap_js, "files", "JavaScript", "Files per Project", "% of Projects", "Hist_files_per_project_js.pdf")
logHistogramFromDF(heatmap_cpp, "files", "C++", "Files per Project", "% of Projects", "Hist_files_per_project_cpp.pdf")
logHistogramFromDF(heatmap_java, "files", "Java", "Files per Project", "% of Projects", "Hist_files_per_project_java.pdf")
logHistogramFromDF(heatmap_python, "files", "Python", "Files per Project", "% of Projects", "Hist_files_per_project_py.pdf")
```

Alternative with 2 datasets for JS

```{r}
logHistogramDouble("SELECT files FROM projects", DB_JS, "all", DB_JS_NONPM, "no NPM", "JavaScript", "Files per Project", "% of projects", "Hist_files_per_project_js2.pdf")
```


## Figure 14 - SLOC per file distributions

> Technically we can do more than 1m samples, but 1m should be enough? 

```{r}
logHistogram("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", "C++", "SLOC", "% of projects", "Hist_sloc_per_file_cpp.pdf", dbname = DB_CPP, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", "Java", "SLOC", "% of projects", "Hist_sloc_per_file_java.pdf", dbname = DB_JAVA, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", "Python", "SLOC", "% of projects", "Hist_sloc_per_file_py.pdf", dbname = DB_PYTHON, username = UCI_USERNAME, password = UCI_PASSWORD, host = UCI_HOST)
logHistogram("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", "JavaScript", "SLOC", "% of projects", "Hist_sloc_per_file_js.pdf")
```

```{r}
logHistogramDouble("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", DB_JS, "all", DB_JS_NONPM, "no NPM", "JavaScript", "SLOC", "% of projects", "Hist_sloc_per_file_js2.pdf")
```

## Figure 15 - stars per project

Data for all languages are in the heatmap.

```{r}
logHistogramFromDF(heatmap_js, "stars", "JavaScript", "Stars", "% of Projects", "Hist_stars_per_project_js.pdf")
logHistogramFromDF(heatmap_cpp, "stars", "C++", "Stars", "% of Projects", "Hist_stars_per_project_cpp.pdf")
logHistogramFromDF(heatmap_java, "stars", "Java", "Stars", "% of Projects", "Hist_stars_per_project_java.pdf")
logHistogramFromDF(heatmap_python, "stars", "Python", "Stars", "% of Projects", "Hist_stars_per_project_python.pdf")
```

```{r}
logHistogramDouble("SELECT stars FROM projects", DB_JS, "all", DB_JS_NONPM, "no NPM", "JavaScript", "Stars", "% of projects", "Hist_stars_per_project_js2.pdf", "SELECT stars FROM projects JOIN js.projects AS x ON projects.projectId = x.projectId WHERE projects.files = x.files")
```

## Figure 16 - commits per project

```{r}
logHistogramFromDF(heatmap_js, "commits", "JavaScript", "Commits", "% of Projects", "Hist_commits_per_project_js.pdf")
logHistogramFromDF(heatmap_cpp, "commits", "C++", "Commits", "% of Projects", "Hist_commits_per_project_cpp.pdf")
logHistogramFromDF(heatmap_java, "commits", "Java", "Commits", "% of Projects", "Hist_commits_per_project_java.pdf")
logHistogramFromDF(heatmap_python, "commits", "Python", "Commits", "% of Projects", "Hist_commits_per_project_python.pdf")
```

Alternate JS version with JS and JS-nonpm:

```{r}
logHistogramDouble("SELECT commits FROM projects", DB_JS, "all", DB_JS_NONPM, "no NPM", "JavaScript", "Commits", "% of projects", "Hist_commits_per_project_js2.pdf", "SELECT commits FROM projects JOIN js.projects AS x ON projects.projectId = x.projectId WHERE projects.files = x.files")
```
